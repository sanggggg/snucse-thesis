\chapter{서론}\label{chap:introduction}

최근 소프트웨어 개발 분야에서 'AI Vibe Coding'으로 대표되는 AI 코딩 에이전트와의 협업은 강력한 선택지가 되어가고 있다. 이러한 변화 속에서 개발자가 AI 도구를 얼마나 '잘' 활용하는지가 생산성에 지대한 영향을 미치기 시작했다. 하지만 사용자의 AI 활용 능력을 객관적으로 측정하고 평가하는 표준화된 지표나 도구는 매우 부족한 실정이다.

시장에 공개된 일부 AI 협업 데이터 분석 도구들은 존재하지만, 대부분 비용, 토큰 사용량 같은 단순 정량 지표에 국한된다. 이러한 지표들은 사용자가 얼마나 많이 AI를 사용했는지는 보여줄 수 있으나, 얼마나 효과적으로 문제를 해결하고, 얼마나 질 높은 상호작용을 했는지는 파악하기 어렵다.

본 연구는 이러한 문제의식에서 출발하여, 사용자의 AI 코딩 에이전트 활용 능력을 심층적으로 측정하기 위한 새로운 접근 방식을 제안한다. 이를 위해 본 연구는 두 가지 주요한 기여를 한다.

첫째, Claude Code, Gemini CLI, Codex 등 다양한 벤더사의 AI 코딩 에이전트로부터 채팅 내역, 비용, 토큰 사용량, 파일 변경 내역 등 다면적인 데이터를 수집하고  아래 점수화 시스템을 통해 리포트화하는 오픈소스 툴킷 'RetroChat'을 개발한다.

둘째, 'RetroChat'을 통해 수집된 채팅 히스토리를 원천 데이터로 삼아, 'LLM-as-a-judge' 방법론을 적용한다. 이는 강력한 LLM(대형 언어 모델)을 '평가자'로 활용하는 과정으로, 단순히 사전에 정의된 기준으로 평가하는 것을 넘어, 지도학습(Supervised learning) 기반의 자동화된 루브릭(rubric) 도출 파이프라인을 구축하는 것을 핵심으로 한다. 이 파이프라인은 토큰 효율성 등 정량적 지표가 높은 채팅 세션들을 학습 데이터로 사용하여, 성공적인 상호작용의 핵심 패턴을 LLM 스스로 학습하고 이를 평가 루브릭으로 생성한다. 이후, 생성된 루브릭을 기반으로 새로운 상호작용의 질을 다각도로 점수화하는 시스템을 구축한다.

본 보고서는 먼저 관련 연구들을 살펴본 뒤, 우리가 제안하는 'RetroChat' 툴킷과 'LLM-as-a-judge' 기반의 AI 활용 능력 평가 시스템의 설계 및 구현 방식을 상세히 설명한다.
