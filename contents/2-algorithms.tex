\chapter{접근 방식}\label{chap:approach}

본 연구의 접근 방식은 크게 두 단계로 구성된다. 첫째, AI 코딩 에이전트와의 상호작용 데이터를 다각도로 수집하기 위한 툴킷 'RetroChat'을 개발한다. 둘째, 수집된 데이터를 기반으로 'LLM-as-a-judge' 방법론을 활용하여 사용자의 AI 활용 능력을 평가하는 시스템을 구축한다.

\section{RetroChat: 다면적 AI 코딩 채팅 분석 툴킷}\label{sec:retrochat}

사용자의 AI 활용 능력을 분석하기 위해서는 먼저 신뢰할 수 있는 원천 데이터의 확보가 필수적이다. 기존 도구들이 제공하는 정량적 지표만으로는 심층적인 분석이 불가능하다고 판단하여, 다면적인 정보를 수집할 수 있는 오픈소스 툴킷 'RetroChat'\footnote{\url{https://github.com/wafflestudio/retrochat}}을 설계 및 구현했다.

\subsection{구현}

'RetroChat'은 Rust 프로그래밍 언어와 Tauri 프레임워크를 기반으로 제작된 Desktop GUI 애플리케이션이다. 이는 직관적인 그래픽 인터페이스를 제공하여 사용자가 자신의 AI 상호작용 데이터를 쉽게 탐색하고 분석할 수 있도록 돕는다. 수집된 모든 사용자 데이터셋은 로컬 SQLite 데이터베이스에 저장되어, 데이터의 프라이버시를 보장하면서 효율적으로 관리된다.

\subsection{주요 기능 및 특징}

\begin{enumerate}[leftmargin=*]
    \item \textbf{다면적 데이터 수집:} 'RetroChat'은 단순한 채팅 로그(Chat History) 스크래핑을 넘어, AI 상호작용과 관련된 다양한 맥락 정보를 수집한다.
    \begin{itemize}
        \item \textbf{Cost \& Token Usage:} API 호출에 따른 비용 및 토큰 사용량.
        \item \textbf{File Changes:} AI의 제안이 실제 프로젝트 파일에 어떤 변경(추가, 삭제, 수정)을 가져왔는지 추적.
        \item \textbf{Chat History:} 사용자와 AI 간의 전체 대화 내용.
        \item \textbf{Tool Use:} AI 가 사용한 Tool 종류 별 사용 횟수.
    \end{itemize}

    \item \textbf{다양한 벤더사 지원:} 현업에서 사용되는 다양한 AI 코딩 에이전트를 지원하는 것을 목표로 한다. 현재 Claude Code, Gemini CLI, Codex 등 주요 벤더사의 채팅 로그 형식을 파싱하고 분석할 수 있다.

    \item \textbf{LLM-as-a-judge 기반 리포트화:} 수집된 원천 데이터를 단순히 나열하는 것이 아니라, 후술할 \ref{sec:llm_judge}절의 LLM-as-a-judge 방법론을 내장하여, 수집된 데이터를 바탕으로 사용자의 상호작용 패턴을 분석하고 평가하는 요약 리포트를 생성한다.
\end{enumerate}

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/retrochat_chat_session.png}
        \caption{채팅 세션 목록 화면}
    \end{subfigure}

    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/retrochat_chat_analysis_1.png}
        \caption{분석 결과 화면 1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/retrochat_chat_analysis_2.png}
        \caption{분석 결과 화면 2}
    \end{subfigure}

    \caption{RetroChat 사용자 화면. 채팅 세션 목록 및 분석 결과 화면}
    \label{fig:retrochat}
\end{figure}

\section{LLM-as-a-judge 기반 사용자 AI 활용 능력 평가}\label{sec:llm_judge}

'RetroChat'을 통해 수집된 채팅 히스토리 데이터는 사용자의 AI 활용 능력을 평가하기 위한 핵심 원천 데이터가 된다. 본 연구는 이 정성적인 텍스트 데이터를 평가하기 위해 'LLM-as-a-judge' 방법론\footnote{\url{https://github.com/sanggggg/retrochat-evalutator}}을 도입했다. 이는 관련 연구인 SPUR가 사용자의 '선호도'를 예측한 것과 달리, 사용자의 '활용 능력(Proficiency)'을 학습 시점에 정량적으로 직접 정의하고 측정 및, 긍정적이거나 부정적인 부분을    판단하여 사용자에게 전달하는 것에 중점을 둔다.

\subsection{평가 시스템 구축 과정}

\begin{enumerate}[leftmargin=*]
    \item \textbf{지도 학습 기반의 AI 활용 능력 루브릭(Rubric) 자동 도출 파이프라인:} 본 연구는 사람이 사전에 루브릭을 정의하는 대신, \ref{sec:chat_eval}절에서 언급된 SPUR 방법론과 유사하게 LLM이 스스로 루브릭을 학습하고 도출하는 방식을 채택한다. 이를 위해 세션의 효율성을 확인할 수 있는 목적 지표들이 함께 주어진 AI 코딩 에이전트 채팅 히스토리 데이터셋을 활용한다. (본 논문에서는 토큰 효율성, 사용자 피드백 효율성 두 가지 목적 지표를 판단하는 루브릭을 도출한다). 지도 학습 파이프라인은 이 데이터셋을 활용하여, 각 판단 지표 별 핵심적인 특징(feature)들을 스스로 학습하여 이를 평가 루브릭으로 생성한다. 예를 들어, LLM은 높은 토큰 활용도의 세션에서 공통적으로 발견되는 '명확한 요구사항 제시', '충분한 맥락 정보 제공', 'AI 제안에 대한 비판적 피드백' 등의 패턴을 학습하여, 이를 '요구사항의 명확성 (Clarity of Prompt)', '맥락 제공 (Context Provision)', '도구 효율적 사용 (Efficient Tool Utilization)' 등의 평가 루브릭으로 생성한다.

    \item \textbf{루브릭 기반의 LLM-as-a-judge 평가:} LLM에 의해 자동 도출된 루브릭을 기반으로, LLM (예: gemini-2.5-flash~\cite{gemini2p5})이 '평가자(Judge)' 역할을 수행하도록 하는 프롬프트를 설계한다. 이 프롬프트는 LLM에게 특정 채팅 히스토리 세션을 입력하여, 학습된 각 루브릭 항목별로 1\textasciitilde5점 척도의 점수를 매기고 그 근거를 서술하도록 지시한다.

    \item \textbf{점수화 시스템 구축:} 2단계에서 LLM-as-a-judge 방법으로 도출한 각 루브릭별 점수(1\textasciitilde5점 척도)는 사용자의 AI 활용 능력을 세부적으로 진단하는 개별 지표로 활용된다. 또한 이 개별 루브릭 점수들의 산술 평균(arithmetic mean)을 계산하여 목적 지표에 대한 예측의 정확성을 검증하는 수단으로도  활용한다. 이 방식은 사용자에게 자신의 강점과 약점이 어떤 루브릭 항목에 있는지 직관적으로 파악하게 함과 동시에, 전반적인 활용 수준을 하나의 점수로 요약하여 검증의 신뢰도를 높이는 데 도움을 준다.
\end{enumerate}

\subsection{지도 학습 기반의 AI 활용 능력 루브릭(Rubric) 자동 도출: 훈련 파이프라인 구현 세부}\label{sec:training_impl}

진행한 훈련의 목적은 정량적 토큰 효율, 사용자 턴 효율 등 세션의 효율성을 확인할 수 있는 지표들을 높은 정확도로 예측해 낼 수 있는 루브릭을 자동으로 도출하는 것이다.

훈련 파이프라인은 대략 다음과 같다. 훈련 데이터 셋에서 목적 지표가 높은 상위 퍼센타일 (상위 15\%) 세션을 선별한 후, 각 세션을 구조화된 대화 세션 JSON 으로 변환한 뒤 루브릭 추출 프롬프트 템플릿을 사용하여 LLM 으로 루브릭을 추출한다. 이후 각 세션 별로 만들어진 3\textasciitilde5개의 루브릭 들을 두 가지 요약 전략(LLM 요약 프롬프트 템플릿을 통한 요약 또는 텍스트 임베딩을 통한 의미론적 클러스터링)을 통해 최종 루브릭을 생성한다. 세부 단계는 다음과 같다

\paragraph{세션 로딩 및 필터링} 데이터셋에서 점수를 기반으로 상위 15\% 퍼센타일을 계산하고, 학습/검증 분리를 유지한 채 필요한 세션만 불러온다. 이를 통해 대규모 로그 중에서도 신뢰도 높은 세션만 선별적으로 학습에 투입한다.

\paragraph{루브릭 추출} 루브릭 추출기는 각 세션을 JSON 문맥으로 포맷하고, 최소·최대 루브릭 개수를 명시해 Gemini 2.5 Flash 모델과 별도의 루브릭 추출 스크립트로 루브릭을 추출한다. 추출 결과는 JSON 배열 형태로 세션당 0\textasciitilde5개의 루브릭을 확보한다. 루브릭 추출 스크립트의 전체 구현 및 프롬프트 템플릿은 부록~\ref{appendix:rubric-extraction}에 수록하였다.

\paragraph{루브릭 통합} 수집된 수십\textasciitilde수백 개의 루브릭은 두 가지 전략으로 정제된다. 기본 전략은 요약 전용 프롬프트를 사용해 3\textasciitilde10개의 대표 기준으로 재구성하는 방식이며, context window가 과도하게 큰 경우 SPUR와 유사한 형태로 재귀적으로 100개 단위로 분할하여 summarize를 수행한다. 다른 전략은 Google 텍스트 임베딩 모델 gemini-embedding-001~\cite{gemini-embedding-001} 과 UMAP + HDBSCAN을 결합한 의미론적 클러스터링을 적용해 유사 루브릭을 자동 병합한다. UMAP을 통한 차원 축소와 HDBSCAN 클러스터링의 조합은 밀도에 따른 유연한 군집화와 고차원 임베딩 데이터에 대한 원활한 클러스터링을 가능하게 한다~\cite{hdbscan}. 군집 크기는 패턴의 빈도를 의미하므로 사용자의 공통 행동 양상이 자연스럽게 강조된다. 요약 전용 프롬프트를 통한 루브릭 통합 과정의 세부 구현 및 실제 프롬프트는 부록~\ref{appendix:rubric-merge}에 추가로 수록하였다.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/rubric_extraction.png}
    \caption{지도 학습 기반의 Rubric 자동 도출 과정}
    \label{fig:rubric_extraction}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/rubric_summarization.png}
    \caption{루브릭 통합 과정 (LLM 요약 및 의미론적 클러스터링)}
    \label{fig:rubric_summarization}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/scoring_unseen_chat_session.png}
    \caption{학습된 Rubric 기반의 채팅 평가}
    \label{fig:chat_assessment}
\end{figure}
